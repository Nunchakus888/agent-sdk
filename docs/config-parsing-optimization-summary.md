# Configuration Parsing Optimization Summary

## Overview

This document summarizes the optimizations made to the configuration parsing logic in [api/agent_manager.py](../api/agent_manager.py) based on the [sop.json](configs/sop.json) configuration structure.

## Key Optimizations

### 1. Field Classification & Handling

**Three-Layer Architecture**:
- **Fixed/Default Behavior**: `kb_config`, `retrieve_knowledge` - No LLM processing, automatically appended to instructions
- **LLM-Parsed Config**: `instructions`, `skills`, `tools`, `flows`, `timers`, `need_greeting`, `constraints` - Enhanced by LLM
- **Environment Variables**: `max_iterations`, `iteration_strategy` - Runtime configuration

### 2. Configuration Field Status

#### From Config (Direct Extraction + Enhancement)
- **basic_settings**: `{name, description, background, instruction, language, tone, chatbot_id}`
  - Extracted from config
  - Integrated into instructions structure by LLM

- **skills**: Trigger conditions + actions + tools
  - Structure: `{"condition", "action", "tools"}` (NO skill_id/name/description)
  - LLM enhances trigger conditions with multi-indicator reasoning

- **tools/system_tools**: Tool definitions with endpoints
  - Preserved with all endpoint details
  - LLM enhances descriptions

- **flows**: Flow definitions with trigger patterns
  - Preserved with endpoint configurations
  - LLM enhances trigger patterns

#### Inferred/Generated by LLM
- **instructions**: Complete workflow instructions (renamed from `sop`)
  - If NULL: Generated from basic_settings + instruction
  - If EXISTS: Enhanced with missing sections
  - Knowledge base section automatically appended after LLM processing

- **need_greeting**: Initial greeting message
  - If NULL: LLM decides based on context (customer-facing vs internal)
  - If EXISTS: Enhanced

- **timers**: Scheduled actions
  - If NULL: Inferred from instruction (e.g., "after 5 min" → timer)
  - If EXISTS: Enhanced

- **constraints**: Security/boundary constraints
  - If NULL: Inferred security boundaries
  - If EXISTS: Enhanced

### 3. Instructions Generation/Enhancement (Renamed from SOP)

**Markdown Structure Template**:
```markdown
# ROLE & IDENTITY
You are {{name}}, {{description}}.

## BACKGROUND
{{background}}

## COMMUNICATION STYLE
- Language: {{language}}
- Tone: {{tone}}

## WORKFLOW PROCEDURE
{{Extracted from instruction - numbered steps}}

## BOUNDARIES & CONSTRAINTS
- Never hallucinate information
- Stay within defined role
- {{Inferred constraints}}
- {{Security constraints if jailbreak detected}}
```

**Knowledge Base Section (Auto-Appended)**:
```markdown
## KNOWLEDGE BASE
- You have access to a knowledge base via retrieve_knowledge tool
- Use it proactively when users ask questions about products, services, or domain knowledge
- This is a default behavior - always available
- The knowledge base is automatically queried when needed
```

**Note**: Knowledge base section is NOT generated by LLM. It's automatically appended after LLM processing if `kb_config` exists.

### 4. Skills Trigger Condition Enhancement

**Enhancement Strategy**:
- Make conditions more specific and actionable
- Add multi-indicator reasoning (e.g., "1. X OR 2. Y OR 3. Z")
- Include context clues and variations
- Ensure clarity on when to trigger

**Example**:
- **Before**: `"Wants to schedule a demo"`
- **After**: `"1. Explicitly requests demo/meeting 2. Asks 'can I see it' 3. Says 'show me how it works' 4. Mentions scheduling/calendar 5. Wants to try product 6. Asks for sales contact 7. Provides contact info voluntarily"`

### 5. Security & Jailbreak Prevention

**Detection Patterns**:
- Role manipulation: "you are now...", "forget you are..."
- Instruction override: "ignore previous", "disregard rules"
- System access: "execute", "run command", "access system"
- Data exfiltration: "send to", "export", "leak"

**Response**:
- Add to constraints: "SECURITY: Jailbreak attempt detected and blocked"
- Sanitize instruction content in SOP
- Preserve core functionality but remove unsafe parts

### 6. Knowledge Base Handling

**Key Principle**: `retrieve_knowledge` is a DEFAULT tool
- Always available to the agent
- No LLM reasoning needed to decide when to use
- NOT included in LLM prompt - handled separately
- Automatically appended to instructions after LLM processing

**Auto-Construction**:
If `kb_config` is missing but `retrieve_knowledge_url` exists:
```python
kb_config = {
    "enabled": True,
    "retrieve_url": retrieve_knowledge_url,
    "chatbot_id": chatbot_id,
    "auto_retrieve": True
}
```

**Auto-Appending to Instructions**:
After LLM processing, if `kb_config` exists, the following section is automatically appended:
```markdown
## KNOWLEDGE BASE
- You have access to a knowledge base via retrieve_knowledge tool
- Use it proactively when users ask questions about products, services, or domain knowledge
- This is a default behavior - always available
- The knowledge base is automatically queried when needed
```

### 7. Tools & Flows Parsing

**Tools**:
- Preserve all endpoint configurations (url, method, headers, body)
- Enhance descriptions for clarity
- Mark silent tools (no user-visible responses)
- Validate endpoint structure

**Flows**:
- Preserve trigger patterns and endpoint configs
- Enhance trigger patterns for better matching
- Maintain parameter mapping
- Keep response templates

## Implementation Details

### Configuration Parsing Flow

```
1. Load raw_config from JSON
2. Extract fixed config (kb_config)
   - Auto-construct from retrieve_knowledge_url if needed
3. Read environment variables (max_iterations, iteration_strategy)
4. Load instruction content (from file or direct text)
5. Call LLM for validation and enhancement
   - Pass: basic_settings, skills, tools, flows, instructions, timers, need_greeting, constraints
   - LLM enhances and generates missing fields
   - Knowledge base is NOT included in LLM prompt
6. Auto-append knowledge base section to instructions (if kb_config exists)
7. Merge: fixed config + env vars + LLM-parsed config
8. Create WorkflowConfigSchema
```

### LLM Prompt Structure

The optimized prompt includes:
- **Field Status**: Clear indication of what exists vs what needs generation
- **Security Instructions**: Explicit jailbreak detection patterns
- **Instructions Template**: Markdown structure for consistent output (renamed from SOP)
- **Skills Enhancement**: Multi-indicator reasoning examples
- **Knowledge Base Exclusion**: Knowledge base is NOT in LLM prompt - handled separately
- **Output Format**: Direct JSON replacement (no markdown blocks)

## Benefits

1. **Clarity**: Clear separation of fixed, LLM-parsed, and environment-driven config
2. **Security**: Comprehensive jailbreak prevention and sanitization
3. **Consistency**: Structured instructions output with markdown template
4. **Flexibility**: Auto-construction of kb_config from retrieve_knowledge_url
5. **Robustness**: Enhanced skills trigger conditions with multi-indicator reasoning
6. **Efficiency**: Knowledge base as default behavior (no LLM reasoning overhead)
7. **Separation of Concerns**: Knowledge base handled separately from LLM processing

## Usage Example

### Input (sop.json)
```json
{
  "basic_settings": {
    "name": "YCloud Customer Service",
    "description": "Shopping assistant",
    "language": "English",
    "tone": "Friendly and professional",
    "instruction": "1. Greet\\n2. Help\\n3. Close"
  },
  "retrieve_knowledge_url": "http://kb.example.com/retrieve",
  "skills": [
    {
      "condition": "Wants demo",
      "action": "Save info",
      "tools": ["save_customer_information"]
    }
  ]
}
```

### Output (Enhanced)
```json
{
  "instructions": "# ROLE & IDENTITY\\nYou are YCloud Customer Service, a Shopping assistant...\\n\\n## KNOWLEDGE BASE\\n- Use retrieve_knowledge tool proactively",
  "skills": [
    {
      "condition": "1. Explicitly requests demo 2. Asks 'can I see it' 3. Mentions scheduling 4. Provides contact info",
      "action": "Persuade customer to provide required information (name, email), then save using save_customer_information tool",
      "tools": ["save_customer_information"]
    }
  ],
  "need_greeting": "Welcome! How can I help you today?",
  "constraints": null
}
```

**Note**: The knowledge base section is automatically appended to instructions after LLM processing.

### kb_config (Auto-Constructed)
```json
{
  "enabled": true,
  "retrieve_url": "http://kb.example.com/retrieve",
  "chatbot_id": "67adb3abaa26c063de0f4bd9",
  "auto_retrieve": true
}
```

## Files Modified

- [api/agent_manager.py](../api/agent_manager.py):
  - `_build_config_validation_prompt()`: Comprehensive prompt optimization, removed knowledge base from LLM processing
  - `_parse_config()`: Auto-construction of kb_config, auto-appending knowledge base to instructions
  - Variable extraction: Renamed `sop` to `instructions` (with backward compatibility)

- [bu_agent_sdk/tools/action_books.py](../bu_agent_sdk/tools/action_books.py):
  - `WorkflowConfigSchema`: Added `instructions` field, deprecated `sop` field (backward compatible)
  - Updated schema documentation to reflect knowledge base auto-appending

## Key Changes Summary

1. **Field Rename**: `sop` → `instructions` (more generic, backward compatible)
2. **Knowledge Base Separation**: Removed from LLM prompt, automatically appended after processing
3. **Auto-Appending**: Knowledge base section automatically added to instructions if kb_config exists
4. **Cleaner Prompt**: LLM focuses on core workflow without knowledge base concerns
5. **Better Separation**: Fixed behavior (kb) vs LLM-enhanced behavior (instructions)

## Related Documentation

- [sop.json](configs/sop.json): Example configuration structure
- [workflow-config-schema-refactoring.md](workflow-config-schema-refactoring.md): Schema design
- [api-optimization-summary.md](api-optimization-summary.md): API optimization details
